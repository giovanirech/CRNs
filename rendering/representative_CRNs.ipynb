{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "taken-marketplace",
   "metadata": {},
   "source": [
    "Lets get representative CRNs from each group for posterior rendering and further evaluation.\n",
    "\n",
    "We will do this by finding the ID of the CRNs with CET which is closest from the average CET of the group to which it belongs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "crucial-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "formed-elite",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET DATA\n",
    "cet_10 = np.loadtxt(\"../VT_fittings/sp2/sp2_10_90.txt\")[:,1:]\n",
    "with open('../VT_fittings/sp2/sp2_10_90.txt','r') as f:\n",
    "    id_10 = [x.split()[0] for x in f.readlines()]\n",
    "\n",
    "cet_20 = np.loadtxt(\"../VT_fittings/sp2/sp2_20_80.txt\")[:,1:]\n",
    "with open('../VT_fittings/sp2/sp2_20_80.txt','r') as f:\n",
    "    id_20 = [x.split()[0] for x in f.readlines()]\n",
    "    \n",
    "cet_30 = np.loadtxt(\"../VT_fittings/sp2/sp2_30_70.txt\")[:,1:]\n",
    "with open('../VT_fittings/sp2/sp2_30_70.txt','r') as f:\n",
    "    id_30 = [x.split()[0] for x in f.readlines()]\n",
    "    \n",
    "cet_40 = np.loadtxt(\"../VT_fittings/sp2/sp2_40_60.txt\")[:,1:]\n",
    "with open('../VT_fittings/sp2/sp2_40_60.txt','r') as f:\n",
    "    id_40 = [x.split()[0] for x in f.readlines()]\n",
    "    \n",
    "cet_50 = np.loadtxt(\"../VT_fittings/sp2/sp2_50_50.txt\")[:,1:]\n",
    "with open('../VT_fittings/sp2/sp2_50_50.txt','r') as f:\n",
    "    id_50 = [x.split()[0] for x in f.readlines()]\n",
    "    \n",
    "cet_60 = np.loadtxt(\"../VT_fittings/sp2/sp2_60_40.txt\")[:,1:]\n",
    "with open('../VT_fittings/sp2/sp2_60_40.txt','r') as f:\n",
    "    id_60 = [x.split()[0] for x in f.readlines()]\n",
    "    \n",
    "cet_70 = np.loadtxt(\"../VT_fittings/sp2/sp2_70_30.txt\")[:,1:]\n",
    "with open('../VT_fittings/sp2/sp2_70_30.txt','r') as f:\n",
    "    id_70 = [x.split()[0] for x in f.readlines()]\n",
    "\n",
    "cet_10 = cet_10*1e6\n",
    "cet_20 = cet_20*1e6\n",
    "cet_30 = cet_30*1e6\n",
    "cet_40 = cet_40*1e6\n",
    "cet_50 = cet_50*1e6\n",
    "cet_60 = cet_60*1e6\n",
    "cet_70 = cet_70*1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "catholic-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVE OUTLIERS\n",
    "data_100 = [cet_10[:,0],cet_20[:,0],cet_30[:,0],cet_40[:,0],cet_50[:,0],cet_60[:,0],cet_70[:,0]]\n",
    "data_300 = [cet_10[:,1],cet_20[:,1],cet_30[:,1],cet_40[:,1],cet_50[:,1],cet_60[:,1],cet_70[:,1]]\n",
    "data_500 = [cet_10[:,2],cet_20[:,2],cet_30[:,2],cet_40[:,2],cet_50[:,2],cet_60[:,2],cet_70[:,2]]\n",
    "\n",
    "ID = [id_10,id_20, id_30, id_40, id_50, id_60, id_70]\n",
    "\n",
    "whis=1.5\n",
    "\n",
    "selected = []\n",
    "excluded = []\n",
    "new_data_100 = []\n",
    "new_data_300 = []\n",
    "new_data_500 = []\n",
    "for n in range(len(data_100)):\n",
    "    cet100 = data_100[n]\n",
    "    Q1_100,Q3_100 = np.percentile(cet100,[25,75])\n",
    "    upper_limit_100 = Q3_100+whis*(Q3_100-Q1_100)\n",
    "    lower_limit_100 = Q1_100-whis*(Q3_100-Q1_100)\n",
    "    \n",
    "    cet300 = data_300[n]\n",
    "    Q1_300,Q3_300 = np.percentile(cet300,[25,75])\n",
    "    upper_limit_300 = Q3_300+whis*(Q3_300-Q1_300)\n",
    "    lower_limit_300 = Q1_300-whis*(Q3_300-Q1_300)\n",
    "    \n",
    "    cet500 = data_500[n]\n",
    "    \n",
    "    ids = []\n",
    "    exc = []\n",
    "    new_cet_100 = []\n",
    "    new_cet_300 = []\n",
    "    new_cet_500 = []\n",
    "    for i in range(len(cet100)):\n",
    "        if (lower_limit_100 < cet100[i] < upper_limit_100) and (lower_limit_300 < cet300[i] < upper_limit_300):\n",
    "            ids.append(ID[n][i])\n",
    "            new_cet_100.append(cet100[i])\n",
    "            new_cet_300.append(cet300[i])\n",
    "            new_cet_500.append(cet500[i])\n",
    "        else:\n",
    "            exc.append(ID[n][i])\n",
    "    selected.append(ids)\n",
    "    excluded.append(exc)\n",
    "    new_data_100.append(new_cet_100)\n",
    "    new_data_300.append(new_cet_300)\n",
    "    new_data_500.append(new_cet_500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "median-helmet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% sp²-C: 0206\n",
      "20% sp²-C: 0844\n",
      "30% sp²-C: 0008\n",
      "40% sp²-C: 0007\n",
      "50% sp²-C: 0006\n",
      "60% sp²-C: 0521\n",
      "70% sp²-C: 1477\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(new_data_300)):\n",
    "    data = new_data_300[i]\n",
    "    average = np.average(data)\n",
    "    closest_id = selected[i][np.argmin(abs(data-average))]\n",
    "    print(f'{10*(i+1)}% sp²-C: {closest_id}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
